{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "###  Data Preparation and Feature Extraction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "import glob\n",
    "\n",
    "# Saving the path of all training data in one list\n",
    "data = glob.glob(\"train\\\\1piano\\\\*\")\n",
    "data.extend(glob.glob(\"train\\\\2guitar\\\\*\"))\n",
    "data.extend(glob.glob(\"train\\\\3violin\\\\*\"))\n",
    "data.extend(glob.glob(\"train\\\\4drum\\\\*\"))\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Create a directory to save MFCC plots\n",
    "output_dir = \"mfcc_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Extracting the features using MFCC\n",
    "for file in data:\n",
    "    audio, rate = librosa.load(file, mono=True, duration=30)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=rate, n_mfcc=15)\n",
    "    mfccs_padded = np.pad(mfccs, pad_width=((0, 0), (0, 500))) # Pad MFCCs for consistent dimensions  \n",
    "    label = int(file.split(\"$\")[1][0])\n",
    "    \n",
    "    X.append(np.mean(mfccs_padded, axis=1)) # Taking the mean to reduce the feature dimensionality \n",
    "    Y.append(label)\n",
    "    \n",
    "    # Save MFCC plot (commented out for now)\n",
    "    #plt.figure(figsize=(10, 4))\n",
    "    #librosa.display.specshow(mfccs, x_axis='time', cmap='Greens')\n",
    "    #plt.colorbar()\n",
    "    #plt.title(f'MFCCs for {file}')\n",
    "    #plt.savefig(os.path.join(output_dir, f'mfcc_plot_{label}_{os.path.basename(file)}.png'))\n",
    "    #plt.close()\n",
    "    \n",
    "# Convert lists to NumPy arrays\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Splitting for Training/Validation Sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Dividing the data into 80% training 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Input Reshaping for Model Compatibility"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reshaping the input to ensure compatibility\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Label Encoding and One-Hot Encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train_encoded, num_classes=4)\n",
    "y_test_onehot = tf.keras.utils.to_categorical(y_test_encoded, num_classes=4)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convolutional Neural Network (CNN) Model Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv1D(32, 3, activation='relu', input_shape=(X_train.shape[1], 1))) # First convolutional layer with 32 filters\n",
    "model.add(layers.BatchNormalization()) #Batch normalization to improve training stability\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(layers.Conv1D(64, 3, activation='relu')) # Second convolutional layer with 64 filters\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu')) \n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(4, activation='softmax')) # Fully connected output layer with 4 neurons and softmax activation\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model using 40 epochs\n",
    "epochs = 40\n",
    "trained_model = model.fit(X_train, y_train_onehot, epochs=epochs, validation_data=(X_test, y_test_onehot))\n",
    "\n",
    "# Evaluate and print the validation accuracy\n",
    "accuracy = model.evaluate(X_test, y_test_onehot)[1]\n",
    "print(f\"Validation Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plotting Training and Validation Curves"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot training and validation loss curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(trained_model.history['loss'])\n",
    "plt.plot(trained_model.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(trained_model.history['accuracy'])\n",
    "plt.plot(trained_model.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "\n",
    "# Save the plots\n",
    "plt.savefig('training_validation_curvesAT30.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Evaluation and Confusion Matrix Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "cm = confusion_matrix(np.argmax(y_test_onehot, axis=1), y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Piano', 'Guitar', 'Violin', 'Drum'])\n",
    "disp.plot(cmap=plt.cm.Greens, values_format=\".0f\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Summary and Saving"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.summary()\n",
    "model.save(\"Musical_Instruments_Detection_CNNModel.keras\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
